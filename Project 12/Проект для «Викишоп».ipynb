{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Лемматизация-твитов\" data-toc-modified-id=\"Лемматизация-твитов-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Лемматизация твитов</a></span></li><li><span><a href=\"#Определим-признаки-и-целевой-признак\" data-toc-modified-id=\"Определим-признаки-и-целевой-признак-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Определим признаки и целевой признак</a></span></li><li><span><a href=\"#Создадим-мешок-слов-с-учётом-стоп-слов\" data-toc-modified-id=\"Создадим-мешок-слов-с-учётом-стоп-слов-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Создадим мешок слов с учётом стоп-слов</a></span></li><li><span><a href=\"#Проверим-распределение-между-классами\" data-toc-modified-id=\"Проверим-распределение-между-классами-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Проверим распределение между классами</a></span></li><li><span><a href=\"#Вывод:\" data-toc-modified-id=\"Вывод:-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Вывод:</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Линейная-регрессия.-Подбор-гиперпараметров\" data-toc-modified-id=\"Линейная-регрессия.-Подбор-гиперпараметров-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Линейная регрессия. Подбор гиперпараметров</a></span></li><li><span><a href=\"#Обучение-модели-LogisticRegression-на-подобранных-гиперпараметрах\" data-toc-modified-id=\"Обучение-модели-LogisticRegression-на-подобранных-гиперпараметрах-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Обучение модели LogisticRegression на подобранных гиперпараметрах</a></span></li><li><span><a href=\"#Модель-DecisionTreeClassifier.-Подбор-гипперпараметров\" data-toc-modified-id=\"Модель-DecisionTreeClassifier.-Подбор-гипперпараметров-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Модель DecisionTreeClassifier. Подбор гипперпараметров</a></span></li><li><span><a href=\"#Обучение-модели-DecisionTreeClassifier-на-подобранных-гиперпараметрах\" data-toc-modified-id=\"Обучение-модели-DecisionTreeClassifier-на-подобранных-гиперпараметрах-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Обучение модели DecisionTreeClassifier на подобранных гиперпараметрах</a></span></li><li><span><a href=\"#Обучение-модели-CatBoostClassifier\" data-toc-modified-id=\"Обучение-модели-CatBoostClassifier-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Обучение модели CatBoostClassifier</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span><ul class=\"toc-item\"><li><span><a href=\"#Проверка-линейной-регрессии-на-тестовых-данных.\" data-toc-modified-id=\"Проверка-линейной-регрессии-на-тестовых-данных.-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Проверка линейной регрессии на тестовых данных.</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Подключим библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "#Загрузим датасет\n",
    "toxic_comments = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "\n",
    "#Отобразим первые 5 строк таблицы\n",
    "display(toxic_comments.head(5))\n",
    "\n",
    "#Посмотрим информацию о таблице\n",
    "toxic_comments.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация твитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic                                          lemm_text\n",
       "0      0  Explanation\\nWhy the edits made under my usern...\n",
       "1      0  D'aww! He matches this background colour I'm s...\n",
       "2      0  Hey man, I'm really not trying to edit war. It...\n",
       "3      0  \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4      0  You, sir, are my hero. Any chance you remember..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Проведем лемматизацию твитов\n",
    "m = Mystem() \n",
    "\n",
    "def lemmatize(text):\n",
    "    lem = m.lemmatize(text)\n",
    "    lem_join = \"\".join(lem)\n",
    "    return lem_join\n",
    "    \n",
    "toxic_comments['lemm_text'] = toxic_comments['text'].apply(lemmatize)\n",
    "toxic_comments = toxic_comments.drop(['text'], axis=1)\n",
    "display(toxic_comments.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определим признаки и целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = toxic_comments['toxic']\n",
    "features = toxic_comments.drop(['toxic'], axis=1)\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=0.4, random_state=12345)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, target_valid, test_size=0.5,random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим мешок слов с учётом стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95742, 139581)\n",
      "(31914, 139581)\n",
      "(31915, 139581)\n"
     ]
    }
   ],
   "source": [
    "#Создадим мешок слов с учётом стоп-слов\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords) \n",
    "\n",
    "features_train = count_tf_idf.fit_transform(features_train['lemm_text'].values.astype('U'))\n",
    "features_valid = count_tf_idf.transform(features_valid['lemm_text'].values.astype('U'))\n",
    "features_test = count_tf_idf.transform(features_test['lemm_text'].values.astype('U'))\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим распределение между классами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Посмотрим распределение между 0 и 1\n",
    "display(toxic_comments['toxic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Так как распределение классов отличается более, чем в 8 раз. В этом случае изменим веса\n",
    "class_ratio = toxic_comments['toxic'].value_counts()[0] / toxic_comments['toxic'].value_counts()[1]\n",
    "class_weight={0:1, 1:class_ratio}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет был загружен, после чего произведена лемматизация твитов. Произведено определние признаков и целевого признака, псоле чего датасет разделен в пропорции 60\\20\\20. После проверки распределния между классами 0 и 1 выяснилось, что распределение отличается более чем в 8 раз. В сявзи с чем были изменены веса. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия. Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель LogisticRegression:\n",
      "\n",
      "{'C': 10, 'class_weight': {0: 1, 1: 8.834884437596301}, 'solver': 'newton-cg'}\n",
      "\n",
      "Выборка гиперпараметров:\n",
      "\n",
      "0.711060 for {'C': 0.1, 'class_weight': {0: 1, 1: 8.834884437596301}, 'solver': 'newton-cg'}\n",
      "0.711092 for {'C': 0.1, 'class_weight': {0: 1, 1: 8.834884437596301}, 'solver': 'lbfgs'}\n",
      "0.711181 for {'C': 0.1, 'class_weight': {0: 1, 1: 8.834884437596301}, 'solver': 'liblinear'}\n",
      "0.750942 for {'C': 1, 'class_weight': {0: 1, 1: 8.834884437596301}, 'solver': 'newton-cg'}\n",
      "0.750823 for {'C': 1, 'class_weight': {0: 1, 1: 8.834884437596301}, 'solver': 'lbfgs'}\n",
      "0.751038 for {'C': 1, 'class_weight': {0: 1, 1: 8.834884437596301}, 'solver': 'liblinear'}\n",
      "0.764250 for {'C': 10, 'class_weight': {0: 1, 1: 8.834884437596301}, 'solver': 'newton-cg'}\n",
      "0.763967 for {'C': 10, 'class_weight': {0: 1, 1: 8.834884437596301}, 'solver': 'lbfgs'}\n",
      "0.764250 for {'C': 10, 'class_weight': {0: 1, 1: 8.834884437596301}, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "#Подбор гиперпараметров\n",
    "model_LR = LogisticRegression()\n",
    "hparams = [{'solver':['newton-cg', 'lbfgs', 'liblinear'],\n",
    "                'C':[0.1, 1, 10],\n",
    "                'class_weight':[class_weight]}]\n",
    "\n",
    "clf = GridSearchCV(model_LR, hparams, scoring='f1',cv=3)\n",
    "clf.fit(features_train, target_train)\n",
    "print(\"Лучшая модель LogisticRegression:\\n\")\n",
    "\n",
    "LR_best_params = clf.best_params_\n",
    "print(LR_best_params)\n",
    "print()\n",
    "print(\"Выборка гиперпараметров:\\n\")\n",
    "\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.6f for %r\"% (mean, params))\n",
    "\n",
    "cv_f1_LR = max(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели LogisticRegression на подобранных гиперпараметрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели LogisticRegression: 0.7707129094412332\n"
     ]
    }
   ],
   "source": [
    "#Обучение модели LogisticRegression на подобранных гиперпараметрах:\n",
    "model_LR = LogisticRegression()\n",
    "model_LR.set_params(**LR_best_params)\n",
    "model_LR.fit(features_train, target_train)\n",
    "target_predict = model_LR.predict(features_valid)\n",
    "valid_f1_LR = f1_score(target_valid, target_predict)\n",
    "print('F1 модели LogisticRegression:', valid_f1_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель DecisionTreeClassifier. Подбор гипперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры модели DecisionTreeClassifier:\n",
      "\n",
      "{'class_weight': {0: 1, 1: 8.834884437596301}, 'max_depth': 47, 'random_state': 12345}\n",
      "\n",
      "Выборка гиперпараметров:\n",
      "\n",
      "0.596525 for {'class_weight': {0: 1, 1: 8.834884437596301}, 'max_depth': 20, 'random_state': 12345}\n",
      "0.603322 for {'class_weight': {0: 1, 1: 8.834884437596301}, 'max_depth': 23, 'random_state': 12345}\n",
      "0.611908 for {'class_weight': {0: 1, 1: 8.834884437596301}, 'max_depth': 26, 'random_state': 12345}\n",
      "0.617481 for {'class_weight': {0: 1, 1: 8.834884437596301}, 'max_depth': 29, 'random_state': 12345}\n",
      "0.613159 for {'class_weight': {0: 1, 1: 8.834884437596301}, 'max_depth': 32, 'random_state': 12345}\n",
      "0.621410 for {'class_weight': {0: 1, 1: 8.834884437596301}, 'max_depth': 35, 'random_state': 12345}\n",
      "0.613035 for {'class_weight': {0: 1, 1: 8.834884437596301}, 'max_depth': 38, 'random_state': 12345}\n",
      "0.612439 for {'class_weight': {0: 1, 1: 8.834884437596301}, 'max_depth': 41, 'random_state': 12345}\n",
      "0.619932 for {'class_weight': {0: 1, 1: 8.834884437596301}, 'max_depth': 44, 'random_state': 12345}\n",
      "0.623894 for {'class_weight': {0: 1, 1: 8.834884437596301}, 'max_depth': 47, 'random_state': 12345}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_DTC = DecisionTreeClassifier()\n",
    "hparams = [{'max_depth':[x for x in range(20,50,3)],'random_state':[12345],'class_weight':[class_weight]}]\n",
    "\n",
    "clf = GridSearchCV(model_DTC, hparams, scoring='f1',cv=3)\n",
    "clf.fit(features_train, target_train)\n",
    "print(\"Лучшие параметры модели DecisionTreeClassifier:\\n\")\n",
    "DTC_best_params = clf.best_params_\n",
    "print(DTC_best_params)\n",
    "\n",
    "print(\"\\nВыборка гиперпараметров:\\n\")\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.6f for %r\"% (mean, params))\n",
    "print()\n",
    "\n",
    "cv_f1_DTC = max(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели DecisionTreeClassifier на подобранных гиперпараметрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели DecisionTreeClassifier: 0.6098719240178444\n"
     ]
    }
   ],
   "source": [
    "#Обучение модели DecisionTreeClassifier на подобранных гиперпараметрах:\n",
    "model_DTC = DecisionTreeClassifier()\n",
    "model_DTC.set_params(**DTC_best_params)\n",
    "model_DTC.fit(features_train, target_train)\n",
    "target_predict = model_DTC.predict(features_valid)\n",
    "valid_f1_DTC = f1_score(target_valid, target_predict)\n",
    "print('F1 модели DecisionTreeClassifier:', valid_f1_DTC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели CatBoostClassifier: 0.7427740410834394\n"
     ]
    }
   ],
   "source": [
    "#Модель CatBoostClassifier\n",
    "model_CBC = CatBoostClassifier(verbose=False, iterations=230)\n",
    "model_CBC.fit(features_train, target_train)\n",
    "target_predict = model_CBC.predict(features_valid)\n",
    "cv_f1_CBC = cross_val_score(model_CBC, features_train, target_train, cv=3, scoring='f1').mean()\n",
    "valid_f1_CBC = f1_score(target_valid, target_predict)\n",
    "print('F1 модели CatBoostClassifier:', valid_f1_CBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Было обучено три модели: \n",
    "\n",
    "- Линейная регрессия\n",
    "- Дерево решений\n",
    "- CatBoostClassifier\n",
    "\n",
    "Так как модель дерево решений имеет низкий показатель f1_score, а модель CatBoostClassifier долго обучается (около 1 часа) и имеет f1_score = 0.74277, что меньше 0.75, то для проверки моделей на тестовых данных будем использовать Линейную регрессию. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка линейной регрессии на тестовых данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели LogisticRegression: 0.7697841726618705\n"
     ]
    }
   ],
   "source": [
    "model_LR = LogisticRegression()\n",
    "model_LR.set_params(**LR_best_params)\n",
    "model_LR.fit(features_train, target_train)\n",
    "predict_test = model_LR.predict(features_test)\n",
    "valid_f1_LR = f1_score(target_test, predict_test)\n",
    "print('F1 модели LogisticRegression:', valid_f1_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Было обучено три модели: \n",
    "\n",
    "- Линейная регрессия\n",
    "- Дерево решений\n",
    "- CatBoostClassifier\n",
    "\n",
    "Так как только Линейная регрессия имеет показатель f1_score больше 0.75, то эта модель была проверена на тестовых данных. В свзяи с тем, что TF-IDF превращает текст в числа, то лучшими моделью стала LogisticRegression, значения f1_score = 0.7697841726618705. Далее следует CatBoostClassifier, но он очень долго обучается (около часа) и на последнем месте Дерево решений. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
